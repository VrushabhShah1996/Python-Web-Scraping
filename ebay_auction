import json
import os
import time
import re
import pandas as pd
from lxml import html
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import logging

# Configure logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.FileHandler('ebay_scraper.log')
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

def get_driver():
    """Initialize and return a Selenium WebDriver instance."""
    options = Options()
    options.add_argument("--headless")
    options.add_argument('--disable-gpu')
    options.add_argument("start-maximized")
    options.add_argument("disable-infobars")
    options.add_argument("--disable-extensions")
    options.add_argument("window-size=1920x1080")
    driver = webdriver.Chrome(options=options)
    logger.info("Initialized WebDriver")
    return driver

def extract_data_from_script(script_text):
    """Extract data from JSON-LD script text."""
    try:
        data = json.loads(script_text)
        return data
    except (json.JSONDecodeError, KeyError) as e:
        logger.error(f"Error extracting data from script: {e}")
        return {}

def get_ebay_data(driver, link):
    """Scrape eBay data from a given URL."""
    try:
        driver.get(link)
        time.sleep(2)  # Allow time for the page to load
        response = driver.page_source
        r = html.fromstring(response)
        
        all_data = ''.join(
            r.xpath("""//script[contains(text(), '"@type":"Product"')][@type="application/ld+json"]//text()""")).strip()
        
        data = extract_data_from_script(all_data)
        
        Bid_count = ''.join(r.xpath('//div[@class="x-buybox__bid-count-section"]//a/span//text()')).replace("[", "").replace("]", "").strip().split(" ")[0]
        domain = data.get("name", '').split(" ")[0].replace("<wbr/>", '')
        currency = data.get("offers", {}).get("priceCurrency", '')
        price = data.get("offers", {}).get("price", '')
        end_date = re.findall('"endTime":{"value":"(.*?)"', response)
        end_date = end_date[0] if end_date else ''
        
        item = {
            "URL": link,
            "Domain": domain,
            "Currency": currency,
            "Current Bid": price,
            "Bid Count": Bid_count,
            "EndDate": end_date
        }
        logger.info(f"Scraped data: {item}")

        if output_format == 1:
            filename = 'ebay_output.csv'
            output_df = pd.DataFrame([item])
            if os.path.exists(filename):
                output_df.to_csv(filename, mode='a', index=False, header=False)
            else:
                output_df.to_csv(filename, mode='a', index=False, header=True)
        elif output_format == 2:
            filename = 'ebay_output.json'
            if os.path.exists(filename):
                with open(filename, 'r', encoding='utf-8') as f:
                    js_data = json.load(f)
                js_data.append(item)
            else:
                js_data = [item]
            with open(filename, 'w', encoding='utf-8') as json_file:
                json.dump(js_data, json_file, indent=4)
        else:
            logger.warning("Invalid output format number. Use 1 for CSV or 2 for JSON.")
    
    except Exception as e:
        logger.error(f"Error processing {link}: {e}")

if __name__ == '__main__':
    output_format = 1  # Set your output format: 1 for CSV, 2 for JSON
    domain_txt_filepath = 'ebay_input.txt'
    all_domain_url = []

    # Read URLs from file
    try:
        with open(domain_txt_filepath, 'r', encoding='utf-8') as file:
            all_domain_url = [line.strip() for line in file if line.strip()]
    except FileNotFoundError:
        logger.error(f"File {domain_txt_filepath} not found.")
        exit(1)

    driver = get_driver()
    for domain_url in all_domain_url:
        get_ebay_data(driver, domain_url)
    
    driver.quit()
    logger.info("Script execution completed.")
